{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping NIPS abstracts from the web\n",
    "\n",
    "This notebook scrapes abstract text from the Proceedings of NIPS archive (html). Abstracts are then stored in a spreadsheet, containing information such as year, authors, title, and abstract.\n",
    "\n",
    "https://papers.nips.cc/\n",
    "\n",
    "There is also a Kaggle dataset of the NIPS proceedings, but the csv looks really messed up after I download it for some reason: https://www.kaggle.com/benhamner/nips-papers#papers.csv\n",
    "\n",
    "So I ended up scraping from NIPS myself anyway. Abstracts were all missing before 2008 so data starts from 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from numpy import sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_NIPS(home_url):\n",
    "    # connect to home page url for that year\n",
    "    year_url = urllib.request.urlopen(home_url).read()\n",
    "    soup = BeautifulSoup(year_url, 'html.parser')\n",
    "    all_links = soup.find_all('a', attrs={'href': re.compile(\"/paper/*\")})    \n",
    "    year = home_url[-4:]    \n",
    "\n",
    "    df_year = pd.DataFrame()\n",
    "    # enumerate through all paper links\n",
    "    for link_idx, link in enumerate(all_links):\n",
    "        # get soup from paper url\n",
    "        url_text = 'https://papers.nips.cc' + str(link['href'])\n",
    "        url = urllib.request.urlopen(url_text).read()\n",
    "        soup = BeautifulSoup(url, 'html.parser')\n",
    "\n",
    "        # scrape & parse\n",
    "        title = ' '.join(soup.find_all('title')[0].text.split())\n",
    "        abstr = ' '.join(soup.find_all('p', {\"class\": \"abstract\"})[0].text.split())\n",
    "        if abstr == 'Abstract Missing':\n",
    "            abstr = ''\n",
    "        authors = ['>'+au['content'] for au in soup.find_all('meta', {\"name\": \"citation_author\"})]\n",
    "\n",
    "        # do some gymnastics to get it into a pandas df and add as a row to CSV\n",
    "        new_row = {'Year': str(year), 'Title': title,'Abstract': abstr,'Authors': ''.join(authors),'Affiliations': ' ', 'URL': url_text}\n",
    "        df_cur = pd.Series(data=new_row).to_frame().T[['Year','Title','Abstract','Authors','Affiliations','URL']]\n",
    "        df_year = df_year.append(df_cur, ignore_index=True)\n",
    "\n",
    "    return df_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over years\n",
    "Scrape and save to individual csvs, then combine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nips_rawfolder = '../data/raw/NIPS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://papers.nips.cc/book/advances-in-neural-information-processing-systems-21-2008\n",
      "https://papers.nips.cc/book/advances-in-neural-information-processing-systems-22-2009\n",
      "https://papers.nips.cc/book/advances-in-neural-information-processing-systems-23-2010\n",
      "https://papers.nips.cc/book/advances-in-neural-information-processing-systems-24-2011\n",
      "https://papers.nips.cc/book/advances-in-neural-information-processing-systems-25-2012\n",
      "https://papers.nips.cc/book/advances-in-neural-information-processing-systems-26-2013\n",
      "https://papers.nips.cc/book/advances-in-neural-information-processing-systems-27-2014\n",
      "https://papers.nips.cc/book/advances-in-neural-information-processing-systems-28-2015\n",
      "https://papers.nips.cc/book/advances-in-neural-information-processing-systems-29-2016\n",
      "https://papers.nips.cc/book/advances-in-neural-information-processing-systems-30-2017\n",
      "https://papers.nips.cc/book/advances-in-neural-information-processing-systems-31-2018\n"
     ]
    }
   ],
   "source": [
    "years = range(2008,2019) # abstracts are in html starting from 2008\n",
    "base_url = 'https://papers.nips.cc/book/advances-in-neural-information-processing-systems-%i-%i'\n",
    "for y_i, year in enumerate(years):\n",
    "    home_url = base_url%(y_i+21, year)\n",
    "    print(home_url)\n",
    "    df_year = scrape_NIPS(home_url)\n",
    "    df_year.to_csv(nips_rawfolder + 'nips_'+str(year)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nips_2008.csv\n",
      "nips_2009.csv\n",
      "nips_2010.csv\n",
      "nips_2011.csv\n",
      "nips_2012.csv\n",
      "nips_2013.csv\n",
      "nips_2014.csv\n",
      "nips_2015.csv\n",
      "nips_2016.csv\n",
      "nips_2017.csv\n",
      "nips_2018.csv\n"
     ]
    }
   ],
   "source": [
    "df_nips = pd.DataFrame()\n",
    "for abstr in sort(os.listdir(nips_rawfolder)):\n",
    "    if '.csv' in abstr:\n",
    "        print(abstr)\n",
    "        df_year = pd.read_csv(nips_rawfolder+abstr)\n",
    "        df_nips=df_nips.append(df_year, ignore_index=True)\n",
    "    \n",
    "df_nips.to_csv('../data/abstracts_nips_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
